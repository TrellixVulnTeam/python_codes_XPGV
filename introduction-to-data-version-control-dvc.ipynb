{
 "cells": [
  {
   "attachments": {
    "dvc.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Version Control\n",
    "\n",
    "\n",
    "\n",
    "In this kernel we are planning to introduce about Data Version Control which one of best open source tools available in the market for [Machine Learning\n",
    "Models and Dataset Versioning](https://dvc.org/doc/use-cases/data-and-model-files-versioning) and [other amazing features](https://dvc.org/features).\n",
    "\n",
    "![dvc.png](attachment:dvc.png)\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to play with an actual Machine Learning scenario. It explores the NLP problem of predicting tags for a given StackOverflow\n",
    "question. For example, we want one classifier which can predict a post that is about the Python language by tagging it python.\n",
    "\n",
    "This kernel has been made adopting [DVC get-Started tutorial](https://dvc.org/doc/get-started/agenda) and full credit goes to DVC team for making that.\n",
    "A github repo for get-starter tutorial can be found [here](https://github.com/iterative/example-get-started)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing DVC\n",
    "\n",
    "Installing DVC is very easy. There are mainly three recommended ways:\n",
    "- pip\n",
    "- OS-specific package managers\n",
    "- HomeBrew(for apple users)\n",
    "\n",
    "\n",
    "We are going to install with `pip- Python package manger`. For other installation\n",
    "methods checkout [here](https://dvc.org/doc/get-started/install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dvc\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/9d/3cf43549b01c80287666d3e251fe3cd4725dcbdf1cbc7e628f83d1e07558/dvc-0.62.0-py2.py3-none-any.whl (275kB)\r\n",
      "\u001b[K     |████████████████████████████████| 276kB 2.9MB/s \r\n",
      "\u001b[?25hCollecting configobj>=5.0.6 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\r\n",
      "Collecting ruamel.yaml>=0.16.1 (from dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/90/ecff85a2e9c497e2fa7142496e10233556b5137db5bd46f3f3b006935ca8/ruamel.yaml-0.16.5-py2.py3-none-any.whl (123kB)\r\n",
      "\u001b[K     |████████████████████████████████| 133kB 33.6MB/s \r\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\r\n",
      "Collecting schema>=0.6.7 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/45/ae/a7e3cc8b885e681cbfee89d8d43dbc0168dbd033e2b2745eda6223477467/schema-0.7.1-py2.py3-none-any.whl\r\n",
      "Collecting distro>=1.3.0 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/35/82f79b92fa4d937146c660a6482cee4f3dfa1f97ff3d2a6f3ecba33e712e/distro-1.4.0-py2.py3-none-any.whl\r\n",
      "Collecting asciimatics>=1.10.0 (from dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/cf/2cf9843608b2d6ee178a04860600b63b4db55a6746adfa46d73cbcd85a7d/asciimatics-1.11.0-py2.py3-none-any.whl (96kB)\r\n",
      "\u001b[K     |████████████████████████████████| 102kB 27.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.35.0 in /opt/conda/lib/python3.6/site-packages (from dvc) (4.36.1)\r\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.6/site-packages (from dvc) (2.3)\r\n",
      "Requirement already satisfied: colorama>=0.3.9 in /opt/conda/lib/python3.6/site-packages (from dvc) (0.4.1)\r\n",
      "Collecting treelib>=1.5.5 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/17/47/0a8e745a1982ca82ef2149903fc77d5bbf08c4d566f8d238dca7eaf59837/treelib-1.5.5.tar.gz\r\n",
      "Requirement already satisfied: future>=0.16.0 in /opt/conda/lib/python3.6/site-packages (from dvc) (0.17.1)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.6/site-packages (from dvc) (1.4.3)\r\n",
      "Collecting inflect>=2.1.0 (from dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/02/e6b11020a9c37d25b4767a1d0af5835629f6e75d6f51553ad07a4c73dc31/inflect-2.1.0-py2.py3-none-any.whl (40kB)\r\n",
      "\u001b[K     |████████████████████████████████| 51kB 16.8MB/s \r\n",
      "\u001b[?25hCollecting configparser>=3.5.0 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: pyasn1>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from dvc) (0.4.7)\r\n",
      "Collecting jsonpath-ng>=1.4.3 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/95/32/ab29fef829c129e5847b8241541bec858515af2bd57a845fad78efde25f5/jsonpath_ng-1.4.3-py2.py3-none-any.whl\r\n",
      "Collecting gitdb2>=2.0.6 (from dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\r\n",
      "\u001b[K     |████████████████████████████████| 71kB 21.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.6/site-packages (from dvc) (2.22.0)\r\n",
      "Collecting grandalf==0.6 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/54/f4/a0b6a4c6d616d0a838b2dd0bc7bf74d73e8e8cdc880bab7fdb5fdc3d0e06/grandalf-0.6-py3-none-any.whl\r\n",
      "Collecting pathspec>=0.6.0 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/68/5902e8cd7f7b17c5879982a3a3ee2ad0c3b92b80c79989a2d3e1ca8d29e1/pathspec-0.6.0.tar.gz\r\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.6/site-packages (from dvc) (41.2.0)\r\n",
      "Requirement already satisfied: humanize>=0.5.1 in /opt/conda/lib/python3.6/site-packages (from dvc) (0.5.1)\r\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/conda/lib/python3.6/site-packages (from dvc) (19.2)\r\n",
      "Requirement already satisfied: funcy>=1.12 in /opt/conda/lib/python3.6/site-packages (from dvc) (1.13)\r\n",
      "Requirement already satisfied: ply>=3.9 in /opt/conda/lib/python3.6/site-packages (from dvc) (3.11)\r\n",
      "Collecting gitpython>=2.1.8 (from dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f8/05f58bd7852dad7edcf70a8de953b4fa39f61cdc13812ae62118be6ffa23/GitPython-3.0.3-py3-none-any.whl (453kB)\r\n",
      "\u001b[K     |████████████████████████████████| 460kB 37.8MB/s \r\n",
      "\u001b[?25hCollecting flufl.lock>=3.2; python_version >= \"3.0\" (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/68/393c148df629f90a919de653ebb967a8bd8c83d07d2bc3150ca0faff3940/flufl.lock-3.2.tar.gz\r\n",
      "Collecting nanotime>=0.5.2 (from dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/54/6d5924f59cf671326e7809f4b3f70fa8df535d67e952ad0b6fea02f52faf/nanotime-0.5.2.tar.gz\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from configobj>=5.0.6->dvc) (1.12.0)\r\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\" (from ruamel.yaml>=0.16.1->dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/77/4bcd63f362bcb6c8f4f06253c11f9772f64189bf08cf3f40c5ccbda9e561/ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548kB)\r\n",
      "\u001b[K     |████████████████████████████████| 552kB 37.0MB/s \r\n",
      "\u001b[?25hCollecting contextlib2==0.5.5 (from schema>=0.6.7->dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from asciimatics>=1.10.0->dvc) (0.1.7)\r\n",
      "Requirement already satisfied: Pillow>=2.7.0 in /opt/conda/lib/python3.6/site-packages (from asciimatics>=1.10.0->dvc) (5.4.1)\r\n",
      "Collecting pyfiglet>=0.7.2 (from asciimatics>=1.10.0->dvc)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/07/fcfdd7a2872f5b348953de35acce1544dab0c1e8368dca54279b1cde5c15/pyfiglet-0.8.post1-py2.py3-none-any.whl (865kB)\r\n",
      "\u001b[K     |████████████████████████████████| 870kB 36.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.1->dvc) (4.4.0)\r\n",
      "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.6->dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dvc) (1.24.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dvc) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dvc) (2.8)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dvc) (3.0.4)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.6/site-packages (from grandalf==0.6->dvc) (2.4.2)\r\n",
      "Collecting atpublic (from flufl.lock>=3.2; python_version >= \"3.0\"->dvc)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/71/125eefdde54cf640eb2c22f868158fb0595fce1512c6c51201b105c44e63/atpublic-1.0.tar.gz\r\n",
      "Building wheels for collected packages: configobj, shortuuid, treelib, pathspec, flufl.lock, nanotime, atpublic\r\n",
      "  Building wheel for configobj (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=df48a2c5452b8031e21f57360ac7d0f5bd8bf293f4af134a86fc04abe904006d\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\r\n",
      "  Building wheel for shortuuid (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=8c87080282d0d1431f1e3c699454eb9d1e7196f43e60bf51f2c3fd9d9232d08e\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\r\n",
      "  Building wheel for treelib (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for treelib: filename=treelib-1.5.5-cp36-none-any.whl size=15518 sha256=d7dd0bed7ec3ba8e90a70d182dc72bfa108082f781c33bfc35fc00a4fbcea280\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/e4/1f/b0/8730974894530362affb8a242aee8f3b42d55ec822c9e2a520\r\n",
      "  Building wheel for pathspec (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pathspec: filename=pathspec-0.6.0-cp36-none-any.whl size=26671 sha256=67b9593b6fa6afdedcaf40e46e3782a31bac625cde896541b6f255cfd8cc3290\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/62/b8/e1/e2719465b5947c40cd85d613d6cb33449b86a1ca5a6c574269\r\n",
      "  Building wheel for flufl.lock (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for flufl.lock: filename=flufl.lock-3.2-cp36-none-any.whl size=19929 sha256=b064760388b02572435f621aa11109404ab377012adc44c73f30b4c14d27ea9b\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/4f/51/d7/f65a7b7f37da7594f7021b122fe677187667ad21f1171d2514\r\n",
      "  Building wheel for nanotime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for nanotime: filename=nanotime-0.5.2-cp36-none-any.whl size=2442 sha256=ae0d54f1520e9d390de34ab65e21fe1cc8309e09065949e56669e45871da6e05\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/41/99/17/7135f635215e1f61e906295afd11f4f791cfe4ab45f3bfdca2\r\n",
      "  Building wheel for atpublic (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for atpublic: filename=atpublic-1.0-cp36-none-any.whl size=4504 sha256=6590c9d4601b89bcb303344ad0b2579b14b7886ff1974489a215d7c5a00b346b\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/e1/26/5d/fb4b06bb9bb028e49b117b9bdb93c9875e751ff52f6b08aa27\r\n",
      "Successfully built configobj shortuuid treelib pathspec flufl.lock nanotime atpublic\r\n",
      "Installing collected packages: configobj, ruamel.yaml.clib, ruamel.yaml, shortuuid, contextlib2, schema, distro, pyfiglet, asciimatics, treelib, inflect, configparser, jsonpath-ng, smmap2, gitdb2, grandalf, pathspec, gitpython, atpublic, flufl.lock, nanotime, dvc\r\n",
      "  Found existing installation: contextlib2 0.6.0\r\n",
      "    Uninstalling contextlib2-0.6.0:\r\n",
      "      Successfully uninstalled contextlib2-0.6.0\r\n",
      "Successfully installed asciimatics-1.11.0 atpublic-1.0 configobj-5.0.6 configparser-4.0.2 contextlib2-0.5.5 distro-1.4.0 dvc-0.62.0 flufl.lock-3.2 gitdb2-2.0.6 gitpython-3.0.3 grandalf-0.6 inflect-2.1.0 jsonpath-ng-1.4.3 nanotime-0.5.2 pathspec-0.6.0 pyfiglet-0.8.post1 ruamel.yaml-0.16.5 ruamel.yaml.clib-0.2.0 schema-0.7.1 shortuuid-0.5.0 smmap2-2.0.5 treelib-1.5.5\r\n"
     ]
    }
   ],
   "source": [
    "# Installing DVC\n",
    "! pip install dvc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: dvc [-h] [-q | -v] [-V] COMMAND ...\r\n",
      "\r\n",
      "Data Version Control\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help     show this help message and exit\r\n",
      "  -q, --quiet    Be quiet.\r\n",
      "  -v, --verbose  Be verbose.\r\n",
      "  -V, --version  Show program's version.\r\n",
      "\r\n",
      "Available Commands:\r\n",
      "  COMMAND        Use dvc COMMAND --help for command-specific help.\r\n",
      "    init         Initialize DVC in the current directory.\r\n",
      "    get          Download data from DVC repository.\r\n",
      "    get-url      Download or copy files from URL.\r\n",
      "    destroy      Remove DVC-files, local DVC config and data cache.\r\n",
      "    add          Take data files or directories under DVC control.\r\n",
      "    remove       Remove DVC-file outputs.\r\n",
      "    move         Rename or move a DVC controlled data file or a directory.\r\n",
      "    unprotect    Unprotect data files or directories.\r\n",
      "    run          Generate a stage file from a command and execute the command.\r\n",
      "    repro        Check for changes and reproduce stages and dependencies.\r\n",
      "    pull         Pull data files from a DVC remote storage.\r\n",
      "    push         Push data files to a DVC remote storage.\r\n",
      "    fetch        Fetch data files from a DVC remote storage.\r\n",
      "    status       Show changed stages, compare local cache and a remote storage.\r\n",
      "    gc           Collect unused data from DVC cache or a remote storage.\r\n",
      "    import       Download data from DVC repository and take it under DVC control.\r\n",
      "    import-url   Download or copy file from URL and take it under DVC control.\r\n",
      "    config       Get or set config options.\r\n",
      "    checkout     Checkout data files from cache.\r\n",
      "    remote       Manage remote storage configuration.\r\n",
      "    cache        Manage cache settings.\r\n",
      "    metrics      Commands to add, manage, collect and display metrics.\r\n",
      "    install      Install DVC git hooks into the repository.\r\n",
      "    root         Relative path to the repository's directory.\r\n",
      "    lock         Lock DVC-files.\r\n",
      "    unlock       Unlock DVC-files.\r\n",
      "    pipeline     Manage pipelines.\r\n",
      "    commit       Save changed data to cache and update DVC-files.\r\n",
      "    diff         Show a diff of a DVC controlled data file or a directory.\r\n",
      "    version      Show DVC version and system/environment information.\r\n",
      "    update       Update data artifacts imported from other DVC repositories.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Checking out DVC installation\n",
    "! dvc -h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising NLP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir get-started && cd get-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "a = Path.cwd() / \"get-started\"\n",
    "os.chdir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /kaggle/working/get-started/.git/\r\n"
     ]
    }
   ],
   "source": [
    "# Initialising git in our folder\n",
    "! git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "You can now commit the changes to git.\r\n",
      "\r\n",
      "\u001b[31m+---------------------------------------------------------------------+\r\n",
      "\u001b[39m\u001b[31m|\u001b[39m                                                                     \u001b[31m|\u001b[39m\r\n",
      "\u001b[31m|\u001b[39m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[39m\r\n",
      "\u001b[31m|\u001b[39m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[39m\r\n",
      "\u001b[31m|\u001b[39m              \u001b[34mhttps://dvc.org/doc/user-guide/analytics\u001b[39m               \u001b[31m|\u001b[39m\r\n",
      "\u001b[31m|\u001b[39m                                                                     \u001b[31m|\u001b[39m\r\n",
      "\u001b[31m+---------------------------------------------------------------------+\r\n",
      "\u001b[39m\r\n",
      "\u001b[33mWhat's next?\u001b[39m\r\n",
      "\u001b[33m------------\u001b[39m\r\n",
      "- Check out the documentation: \u001b[34mhttps://dvc.org/doc\u001b[39m\r\n",
      "- Get help and share ideas: \u001b[34mhttps://dvc.org/chat\u001b[39m\r\n",
      "- Star us on GitHub: \u001b[34mhttps://github.com/iterative/dvc\u001b[39m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Run DVC initialization in a repository directory to create the DVC meta files and directories\n",
    "! dvc init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) 03c1d2b] initialize DVC\r\n",
      " 2 files changed, 9 insertions(+)\r\n",
      " create mode 100644 .dvc/.gitignore\r\n",
      " create mode 100644 .dvc/config\r\n"
     ]
    }
   ],
   "source": [
    "# configuring git for user account\n",
    "! git config --global user.name \"kuranbenoy\" #Replace with your github username\n",
    "! git config --global user.email \"kurian.bkk@gmail.com\" #Replace with your email id\n",
    "# commit the initialised git files\n",
    "! git commit -m \"initialize DVC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring DVC remotes\n",
    "\n",
    "\n",
    "A DVC remote is used to share your ML models and datasets with others. The various types of remotes DVC currently supports is:\n",
    "https://dvc.org/doc/get-started/configure\n",
    "- `local` - Local directory\n",
    "- `s3` - Amazon Simple Storage Service\n",
    "- `gs` - Google Cloud Storage\n",
    "- `azure` - Azure Blob Storage\n",
    "- `ssh` - Secure Shell\n",
    "- `hdfs` - The Hadoop Distributed File System\n",
    "- `http` - Support for HTTP and HTTPS protocolbucks\n",
    "\n",
    "> Note we are using remote as a local directory as storage. **It's usually recommended to use Cloud storage services as DVC remote.**\n",
    "\n",
    "[More information](https://dvc.org/doc/get-started/configure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'myremote' as a default remote.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc remote add -d myremote /tmp/dvc-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 6cf2331] initialize DVC local remote\r\n",
      " 1 file changed, 4 insertions(+)\r\n"
     ]
    }
   ],
   "source": [
    " ! git commit .dvc/config -m \"initialize DVC local remote\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Threaded:\r\n",
      "!\u001b[A\r\n",
      "  0%|          |../../../tmp/tmph1talkvbdvc-rep0/37916850 [00:00<?,        ?B/s]\u001b[A\r\n",
      "  7%|▋         |../../../tmp/tmph1tal2818048/37916850 [00:00<00:01,    24.7MB/s]\u001b[A\r\n",
      " 41%|████      |../../../tmp/tmph1ta15597568/37916850 [00:00<00:00,    32.6MB/s]\u001b[A\r\n",
      " 73%|███████▎  |../../../tmp/tmph1ta27852800/37916850 [00:00<00:00,    41.6MB/s]\u001b[A\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "! mkdir data/\n",
    "!  dvc get https://github.com/iterative/dataset-registry \\\n",
    "        get-started/data.xml -o data/data.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 'data/data.xml' to '.dvc/cache/a3/04afb96060aad90176268345e10355'.\r\n",
      "Saving information to 'data/data.xml.dvc'.\r\n",
      "\r\n",
      "To track the changes with git, run:\r\n",
      "\r\n",
      "\tgit add data/data.xml.dvc data/.gitignore\r\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# add file(directory) to DVC\n",
    "! dvc add data/data.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 333bf47] add source data to DVC\r\n",
      " 2 files changed, 8 insertions(+)\r\n",
      " create mode 100644 data/.gitignore\r\n",
      " create mode 100644 data/data.xml.dvc\r\n"
     ]
    }
   ],
   "source": [
    "# add DVC files to git and update gitignore\n",
    "! git add data/.gitignore data/data.xml.dvc\n",
    "! git commit -m \"add source data to DVC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[more information](https://dvc.org/doc/get-started/add-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Threaded:\r\n",
      "!\u001b[A\r\n",
      "  0%|          |data/data.xml                  0/37916850 [00:00<?,        ?B/s]\u001b[A\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#  push them from your repository to the default remote storage*:\n",
    "! dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data\n",
    "\n",
    "Now since we pushed our data, we are going to do the opposite of push ie `pull` similar to git analogy.\n",
    "An easy way to test it is by removing currently downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -f data/data.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Now your data returns back to repositary\n",
    "! dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# incase just to retrieve single dataset or file\n",
    "! dvc pull data/data.xml.dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conncting with code\n",
    "\n",
    "For providing full Machine Learning reproducibility. It is important to connect code with Datasets which are being reproducible by\n",
    "using commands like `dvc add/push/pull`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /opt/conda/lib/libuuid.so.1: no version information available (required by wget)\r\n",
      "--2019-10-09 16:59:09--  http://wget/\r\n",
      "Resolving wget (wget)... failed: Name or service not known.\r\n",
      "wget: unable to resolve host address ‘wget’\r\n",
      "--2019-10-09 16:59:09--  https://code.dvc.org/get-started/code.zip\r\n",
      "Resolving code.dvc.org (code.dvc.org)... 3.214.163.243, 3.212.234.252, 52.7.140.64, ...\r\n",
      "Connecting to code.dvc.org (code.dvc.org)|3.214.163.243|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: https://s3-us-east-2.amazonaws.com/dvc-public/code/get-started/code.zip [following]\r\n",
      "--2019-10-09 16:59:09--  https://s3-us-east-2.amazonaws.com/dvc-public/code/get-started/code.zip\r\n",
      "Resolving s3-us-east-2.amazonaws.com (s3-us-east-2.amazonaws.com)... 52.219.80.59\r\n",
      "Connecting to s3-us-east-2.amazonaws.com (s3-us-east-2.amazonaws.com)|52.219.80.59|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 3453 (3.4K) [application/zip]\r\n",
      "Saving to: ‘code.zip’\r\n",
      "\r\n",
      "code.zip            100%[===================>]   3.37K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2019-10-09 16:59:10 (94.4 MB/s) - ‘code.zip’ saved [3453/3453]\r\n",
      "\r\n",
      "FINISHED --2019-10-09 16:59:10--\r\n",
      "Total wall clock time: 0.4s\r\n",
      "Downloaded: 1 files, 3.4K in 0s (94.4 MB/s)\r\n",
      "Archive:  code.zip\r\n",
      "  inflating: src/evaluate.py         \r\n",
      "  inflating: src/featurization.py    \r\n",
      "  inflating: src/prepare.py          \r\n",
      "  inflating: src/requirements.txt    \r\n",
      "  inflating: src/train.py            \r\n"
     ]
    }
   ],
   "source": [
    "# run these commands to get the sample code:\n",
    "! wget wget https://code.dvc.org/get-started/code.zip\n",
    "! unzip code.zip\n",
    "! rm -f code.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having installed the `src/prepare.py` script in your repo, the following command\n",
    "transforms it into a reproducible\n",
    "[stage](https://dvc.org/doc/user-guide/dvc-files-and-directories) for the ML pipeline we're\n",
    "building (described in detail [in the documentation](https://dvc.org/doc/get-started/example-pipeline))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stages are run using dvc run [command] and options among which we use:\n",
    "\n",
    "- d for dependency: specify an input file\n",
    "- o for output: specify an output file ignored by git and tracked by dvc\n",
    "- M for metric: specify an output file tracked by git\n",
    "- f for file: specify the name of the dvc file.\n",
    "- command: a bash command, mostly a python script invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\r\n",
      "\tpython src/prepare.py data/data.xml\r\n",
      "Saving 'data/prepared' to '.dvc/cache/68/36f797f3924fb46fcfd6b9f6aa6416.dir'.\r\n",
      "Saving information to 'prepare.dvc'.\r\n",
      "\r\n",
      "To track the changes with git, run:\r\n",
      "\r\n",
      "\tgit add data/.gitignore prepare.dvc\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Create a pipeline to create  folder data/prepared with files train.tsv and test.tsv\n",
    "! dvc run -f prepare.dvc \\\n",
    "          -d src/prepare.py -d data/data.xml \\\n",
    "          -o data/prepared \\\n",
    "          python src/prepare.py data/data.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master de74f92] add data preparation stage\r\n",
      " 2 files changed, 14 insertions(+)\r\n",
      " create mode 100644 prepare.dvc\r\n"
     ]
    }
   ],
   "source": [
    "!  git add data/.gitignore prepare.dvc\n",
    "!  git commit -m \"add data preparation stage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Threaded:\r\n",
      "!\u001b[A\r\n",
      "  0%|          |data/prepared/test.tsv          0/4819529 [00:00<?,        ?B/s]\u001b[A\r\n",
      "\r\n",
      "!\u001b[A\u001b[A\r\n",
      "\r\n",
      "  0%|          |data/prepared                       0/137 [00:00<?,        ?B/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "!\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "  0%|          |data/prepared/train.tsv        0/19041790 [00:00<?,        ?B/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "                                                                                \u001b[A\u001b[A\r\n",
      "\r\n",
      "\u001b[A\u001b[A\r\n",
      "                                                                                \u001b[A\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Using `dvc run` multiple times, and specifying outputs of a command (stage) as dependencies in another one, we can describe a sequence of commands that gets to a desired result.\n",
    "This is what we call a data pipeline or computational graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\r\n",
      "\tpython src/featurization.py data/prepared data/features\r\n",
      "The input data frame data/prepared/train.tsv size is (20110, 3)\r\n",
      "The output matrix data/features/train.pkl size is (20110, 5002) and data type is float64\r\n",
      "The input data frame data/prepared/test.tsv size is (4890, 3)\r\n",
      "The output matrix data/features/test.pkl size is (4890, 5002) and data type is float64\r\n",
      "Saving 'data/features' to '.dvc/cache/8d/5b8ce7a24705fc41f947623cac1860.dir'.\r\n",
      "Saving information to 'featurize.dvc'.\r\n",
      "\r\n",
      "To track the changes with git, run:\r\n",
      "\r\n",
      "\tgit add featurize.dvc data/.gitignore\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Lets create a second stage (after prepare.dvc, created in the previous chapter) to perform feature extraction\n",
    "! dvc run -f featurize.dvc \\\n",
    "          -d src/featurization.py -d data/prepared/ \\\n",
    "          -o data/features \\\n",
    "           python src/featurization.py data/prepared data/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\r\n",
      "\tpython src/train.py data/features model.pkl\r\n",
      "Input matrix size (20110, 5002)\r\n",
      "X matrix size (20110, 5000)\r\n",
      "Y matrix size (20110,)\r\n",
      "Saving 'model.pkl' to '.dvc/cache/43/630cce66a2432dcecddc9dd006d0a7'.\r\n",
      "Saving information to 'train.dvc'.\r\n",
      "\r\n",
      "To track the changes with git, run:\r\n",
      "\r\n",
      "\tgit add .gitignore train.dvc\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# A third stage for training the model\n",
    "! dvc run -f train.dvc \\\n",
    "          -d src/train.py -d data/features \\\n",
    "          -o model.pkl \\\n",
    "          python src/train.py data/features model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master edda4fa] add featurization and train steps to the pipeline\n",
      " 4 files changed, 28 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 featurize.dvc\n",
      " create mode 100644 train.dvc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multi-Threaded:\n",
      "!\n",
      "  0%|          |data/features/test.pkl          0/2285457 [00:00<?,        ?B/s]\n",
      "\n",
      "!\n",
      "\n",
      "  0%|          |data/features                       0/137 [00:00<?,        ?B/s]\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "\n",
      "  0%|          |data/features/train.pkl         0/9241474 [00:00<?,        ?B/s]\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      "  0%|          |model.pkl                       0/6262877 [00:00<?,        ?B/s]\n",
      "\n",
      "\n",
      "                                                                                \r\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \r\n",
      "\n",
      "                                                                                \n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "\r\n",
      "                                                                                \n",
      "\n",
      "\r\n",
      "               \r"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git add data/.gitignore .gitignore featurize.dvc train.dvc\n",
    "git commit -m \"add featurization and train steps to the pipeline\"\n",
    "dvc push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=\u001b[m\u001b[?1h\u001b=\u001b[31mERROR\u001b[39m: unexpected error - curs_set() returned ERR\n",
      "\n",
      "\u001b[33mHaving any troubles?\u001b[39m Hit us up at \u001b[34mhttps://dvc.org/support\u001b[39m, we are always happy to help!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc pipeline show --ascii train.dvc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The last stage we would like to add to our pipeline is its the evaluation. Data science is a metric-driven R&D-like process and `dvc metrics` along with DVC metric \n",
    "files provide a framework to capture and compare experiments performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`evaluate.py` calculates AUC value using the test data set. It reads features from the `features/test.pkl` file and produces a DVC metric file - `auc.metric`. It is a special DVC output file type, in this case it's just a plain text file with a single number inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\r\n",
      "\tpython src/evaluate.py model.pkl data/features auc.metric\r\n",
      "Output 'auc.metric' doesn't use cache. Skipping saving.\r\n",
      "Saving information to 'evaluate.dvc'.\r\n",
      "\r\n",
      "To track the changes with git, run:\r\n",
      "\r\n",
      "\tgit add evaluate.dvc\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc run -f evaluate.dvc \\\n",
    "          -d src/evaluate.py -d model.pkl -d data/features \\\n",
    "          -M auc.metric \\\n",
    "          python src/evaluate.py model.pkl \\\n",
    "                 data/features auc.metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please, refer to the [dvc metrics](https://dvc.org/doc/commands-reference/metrics) command documentation to see more available options and details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 2326886] add evaluation step to the pipeline\n",
      " 2 files changed, 16 insertions(+)\n",
      " create mode 100644 auc.metric\n",
      " create mode 100644 evaluate.dvc\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git add evaluate.dvc auc.metric\n",
    "git commit -m \"add evaluation step to the pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag as a checkpoint to cpmpare further experiments\n",
    "! git tag -a \"baseline-experiment\" -m \"baseline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Data science process is inherently iterative and R&D like - data scientist may try many different approaches, different hyper-parameter values and \"fail\" \n",
    "many times before the required level of a metric is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are modifying our feature extraction of our files. Inorder to use `bigrams`. We are increasing no of features and n_gram_range in our file `src/featurization.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/featurization.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/featurization.py\n",
    "import os\n",
    "import sys\n",
    "import errno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if len(sys.argv) != 3 and len(sys.argv) != 5:\n",
    "    sys.stderr.write('Arguments error. Usage:\\n')\n",
    "    sys.stderr.write('\\tpython featurization.py data-dir-path features-dir-path\\n')\n",
    "    sys.exit(1)\n",
    "\n",
    "train_input = os.path.join(sys.argv[1], 'train.tsv')\n",
    "test_input = os.path.join(sys.argv[1], 'test.tsv')\n",
    "train_output = os.path.join(sys.argv[2], 'train.pkl')\n",
    "test_output = os.path.join(sys.argv[2], 'test.pkl')\n",
    "\n",
    "try:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "def get_df(data):\n",
    "    df = pd.read_csv(\n",
    "        data,\n",
    "        encoding='utf-8',\n",
    "        header=None,\n",
    "        delimiter='\\t',\n",
    "        names=['id', 'label', 'text']\n",
    "    )\n",
    "    sys.stderr.write('The input data frame {} size is {}\\n'.format(data, df.shape))\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_matrix(df, matrix, output):\n",
    "    id_matrix = sparse.csr_matrix(df.id.astype(np.int64)).T\n",
    "    label_matrix = sparse.csr_matrix(df.label.astype(np.int64)).T\n",
    "\n",
    "    result = sparse.hstack([id_matrix, label_matrix, matrix], format='csr')\n",
    "\n",
    "    msg = 'The output matrix {} size is {} and data type is {}\\n'\n",
    "    sys.stderr.write(msg.format(output, result.shape, result.dtype))\n",
    "\n",
    "    with open(output, 'wb') as fd:\n",
    "        pickle.dump(result, fd, pickle.HIGHEST_PROTOCOL)\n",
    "    pass\n",
    "\n",
    "\n",
    "mkdir_p(sys.argv[2])\n",
    "\n",
    "# Generate train feature matrix\n",
    "df_train = get_df(train_input)\n",
    "train_words = np.array(df_train.text.str.lower().values.astype('U'))\n",
    "\n",
    "bag_of_words = CountVectorizer(stop_words='english',\n",
    "                               max_features=5000,\n",
    "                              ngram_range=(1, 2),)\n",
    "bag_of_words.fit(train_words)\n",
    "train_words_binary_matrix = bag_of_words.transform(train_words)\n",
    "tfidf = TfidfTransformer(smooth_idf=False)\n",
    "tfidf.fit(train_words_binary_matrix)\n",
    "train_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n",
    "\n",
    "save_matrix(df_train, train_words_tfidf_matrix, train_output)\n",
    "\n",
    "# Generate test feature matrix\n",
    "df_test = get_df(test_input)\n",
    "test_words = np.array(df_test.text.str.lower().values.astype('U'))\n",
    "test_words_binary_matrix = bag_of_words.transform(test_words)\n",
    "test_words_tfidf_matrix = tfidf.transform(test_words_binary_matrix)\n",
    "\n",
    "save_matrix(df_test, test_words_tfidf_matrix, test_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce\n",
    "\n",
    "We described our first pipeline. Basically, we created a number of DVC-file. Each file describes a single stage we need to run (a pipeline) towards a final result.\n",
    "Each depends on some data (either source data files or some intermediate results from another DVC-file file) and code files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING\u001b[39m: Dependency 'src/featurization.py' of 'featurize.dvc' changed because it is 'modified'.\r\n",
      "\u001b[33mWARNING\u001b[39m: Stage 'featurize.dvc' changed.\r\n",
      "Running command:\r\n",
      "\tpython src/featurization.py data/prepared data/features\r\n",
      "The input data frame data/prepared/train.tsv size is (20110, 3)\r\n",
      "The output matrix data/features/train.pkl size is (20110, 5002) and data type is float64\r\n",
      "The input data frame data/prepared/test.tsv size is (4890, 3)\r\n",
      "The output matrix data/features/test.pkl size is (4890, 5002) and data type is float64\r\n",
      "Saving 'data/features' to '.dvc/cache/d3/f8d7cdf1f9cd304386e24921649330.dir'.\r\n",
      "Saving information to 'featurize.dvc'.\r\n",
      "\u001b[33mWARNING\u001b[39m: Dependency 'data/features' of 'train.dvc' changed because it is 'modified'.\r\n",
      "\u001b[33mWARNING\u001b[39m: Stage 'train.dvc' changed.\r\n",
      "Running command:\r\n",
      "\tpython src/train.py data/features model.pkl\r\n",
      "Input matrix size (20110, 5002)\r\n",
      "X matrix size (20110, 5000)\r\n",
      "Y matrix size (20110,)\r\n",
      "Saving 'model.pkl' to '.dvc/cache/56/f03228a7d8a499336132ad1edbe5fd'.\r\n",
      "Saving information to 'train.dvc'.\r\n",
      "\r\n",
      "To track the changes with git, run:\r\n",
      "\r\n",
      "\tgit add train.dvc featurize.dvc\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Using DVC Repro here \n",
    "! dvc repro train.dvc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master cb34afa] bigram model\r\n",
      " 2 files changed, 6 insertions(+), 6 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "! git commit -a -m \"bigram model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: checking out 'baseline-experiment'.\r\n",
      "\r\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\r\n",
      "changes and commit them, and you can discard any commits you make in this\r\n",
      "state without impacting any branches by performing another checkout.\r\n",
      "\r\n",
      "If you want to create a new branch to retain commits you create, you may\r\n",
      "do so (now or later) by using -b with the checkout command again. Example:\r\n",
      "\r\n",
      "  git checkout -b <new-branch-name>\r\n",
      "\r\n",
      "HEAD is now at 2326886... add evaluation step to the pipeline\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! git checkout baseline-experiment\n",
    "! dvc checkout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Expermiments\n",
    "\n",
    "DVC makes it easy to iterate on your project using Git commits with tags or Git branches. It provides a way to try different ideas, keep track of them, \n",
    "switch back and forth. To find the best performing experiment or track the progress, a special metric output type is supported in \n",
    "DVC (described in one of the previous steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Dependency 'model.pkl' of 'evaluate.dvc' changed because it is 'modified'.\n",
      "WARNING: Stage 'evaluate.dvc' changed.\n",
      "Running command:\n",
      "\tpython src/evaluate.py model.pkl data/features auc.metric\n",
      "Output 'auc.metric' doesn't use cache. Skipping saving.\n",
      "Saving information to 'evaluate.dvc'.\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add evaluate.dvc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 2326886... add evaluation step to the pipeline\n",
      "Switched to branch 'master'\n",
      "  0%|          |Checkout                              0/6 [00:00<?,     ?file/s]\n",
      "!\n",
      "  0%|          |Creating unpacked dir                 0/2 [00:00<?,     ?file/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git checkout master\n",
    "dvc checkout\n",
    "dvc repro evaluate.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 464ccc3] evaluate bigram model\n",
      " 2 files changed, 5 insertions(+), 5 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git commit -a -m \"evaluate bigram model\"\n",
    "git tag -a \"bigram-experiment\" -m \"bigrams\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working tree:\r\n",
      "\tauc.metric: 0.615827\r\n",
      "baseline-experiment:\r\n",
      "\tauc.metric: 0.588426\r\n",
      "bigram-experiment:\r\n",
      "\tauc.metric: 0.615827\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc metrics show -T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get older Data files\n",
    "\n",
    "The answer is the `dvc checkout` command, and we already touched briefly the process of switching between different data versions in the Experiments step of this get started guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! git checkout baseline-experiment train.dvc\n",
    "! dvc checkout train.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: checking out 'baseline-experiment'.\r\n",
      "\r\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\r\n",
      "changes and commit them, and you can discard any commits you make in this\r\n",
      "state without impacting any branches by performing another checkout.\r\n",
      "\r\n",
      "If you want to create a new branch to retain commits you create, you may\r\n",
      "do so (now or later) by using -b with the checkout command again. Example:\r\n",
      "\r\n",
      "  git checkout -b <new-branch-name>\r\n",
      "\r\n",
      "HEAD is now at 2326886... add evaluation step to the pipeline\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! git checkout baseline-experiment\n",
    "! dvc checkout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------\n",
    "\n",
    "- https://dvc.org/doc/get-started\n",
    "- https://medium.com/qonto-engineering/using-dvc-to-create-an-efficient-version-control-system-for-data-projects-96efd94355fe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
